{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обычные-модели\" data-toc-modified-id=\"Обычные-модели-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Обычные модели</a></span></li><li><span><a href=\"#Градиентные-модели\" data-toc-modified-id=\"Градиентные-модели-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Градиентные модели</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества _F1_ не меньше 0.75.\n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели.\n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять _BERT_ необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец _text_ в нём содержит текст комментария, а _toxic_ — целевой признак.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель** данной работы - решение задачи классификации с целью определения токсичных комментариев.\n",
    "\n",
    "Для её реализации были выполнены следующие **задачи**:\n",
    "\n",
    "1. Загрузить и провести предобработку данных;\n",
    "2. Обучить и провести оптимизацию нескольких моделей, для обеспечения метрики f1 не меньше, чем 0.75.\n",
    "3. Сделать выводы по проделанной работе.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем и подключаем необходимые библиотеки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:34.956994Z",
     "iopub.status.busy": "2023-02-20T11:26:34.956994Z",
     "iopub.status.idle": "2023-02-20T11:26:38.771238Z",
     "shell.execute_reply": "2023-02-20T11:26:38.771238Z",
     "shell.execute_reply.started": "2023-02-20T11:26:34.956994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install catboost==1.1.1 -q\n",
    "!pip install --upgrade scikit-learn --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:38.774226Z",
     "iopub.status.busy": "2023-02-20T11:26:38.773229Z",
     "iopub.status.idle": "2023-02-20T11:26:41.177064Z",
     "shell.execute_reply": "2023-02-20T11:26:41.176067Z",
     "shell.execute_reply.started": "2023-02-20T11:26:38.774226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import gdown\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    PassiveAggressiveClassifier,\n",
    "    SGDClassifier,\n",
    "    RidgeClassifier,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные надстройки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:41.178061Z",
     "iopub.status.busy": "2023-02-20T11:26:41.178061Z",
     "iopub.status.idle": "2023-02-20T11:26:41.691809Z",
     "shell.execute_reply": "2023-02-20T11:26:41.691809Z",
     "shell.execute_reply.started": "2023-02-20T11:26:41.178061Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vovan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vovan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vovan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "RND = 555\n",
    "np.random.seed(RND)\n",
    "nltk.download(['stopwords', 'wordnet', 'omw-1.4'])\n",
    "stopwords = list(set(nltk_stopwords.words('english')))\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем и изучаем датасет\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:41.693803Z",
     "iopub.status.busy": "2023-02-20T11:26:41.693803Z",
     "iopub.status.idle": "2023-02-20T11:26:49.129712Z",
     "shell.execute_reply": "2023-02-20T11:26:49.128713Z",
     "shell.execute_reply.started": "2023-02-20T11:26:41.693803Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://code.s3.yandex.net/datasets/toxic_comments.csv\")\n",
    "df = df.iloc[:, 1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:49.131708Z",
     "iopub.status.busy": "2023-02-20T11:26:49.130709Z",
     "iopub.status.idle": "2023-02-20T11:26:49.176364Z",
     "shell.execute_reply": "2023-02-20T11:26:49.175536Z",
     "shell.execute_reply.started": "2023-02-20T11:26:49.131708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим распределение меток\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:49.177362Z",
     "iopub.status.busy": "2023-02-20T11:26:49.177362Z",
     "iopub.status.idle": "2023-02-20T11:26:49.192321Z",
     "shell.execute_reply": "2023-02-20T11:26:49.191379Z",
     "shell.execute_reply.started": "2023-02-20T11:26:49.177362Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы несбалансированы, токсичных всего 10 %. Проводить апсемплинг данных с таким количеством строк неразумно, поэтому в для корректного построения моделей будем использовать параметр class_weights='balansed'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:49.194351Z",
     "iopub.status.busy": "2023-02-20T11:26:49.194351Z",
     "iopub.status.idle": "2023-02-20T11:26:49.208281Z",
     "shell.execute_reply": "2023-02-20T11:26:49.207319Z",
     "shell.execute_reply.started": "2023-02-20T11:26:49.194351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159287  \":::::And for the second time of asking, when ...      0\n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290  And it looks like it was actually you who put ...      0\n",
       "159291  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные требуют обработки, а именно очистки и лемматизации для дальнейшего упрощения моделирования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:49.209278Z",
     "iopub.status.busy": "2023-02-20T11:26:49.209278Z",
     "iopub.status.idle": "2023-02-20T11:26:49.224273Z",
     "shell.execute_reply": "2023-02-20T11:26:49.223276Z",
     "shell.execute_reply.started": "2023-02-20T11:26:49.209278Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(\"\\W\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = re.sub(\"\\d+\", \" \", text)\n",
    "    text = text.strip(\" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем очистку и лемматизацию, исключая ненужные слова\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:26:49.225236Z",
     "iopub.status.busy": "2023-02-20T11:26:49.225236Z",
     "iopub.status.idle": "2023-02-20T11:28:05.006017Z",
     "shell.execute_reply": "2023-02-20T11:28:05.005019Z",
     "shell.execute_reply.started": "2023-02-20T11:26:49.225236Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wnl = WordNetLemmatizer()\n",
    "df['lemm_text'] = df['text'].str.lower().map(lambda sen: clean_text(sen))\n",
    "df['lemm_text'] = df['lemm_text'].str.split().apply(lambda sen: ' '.join(\n",
    "    [wnl.lemmatize(word) for word in sen if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим эффективность предобработки на одной из строк\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:28:05.007015Z",
     "iopub.status.busy": "2023-02-20T11:28:05.007015Z",
     "iopub.status.idle": "2023-02-20T11:28:05.020977Z",
     "shell.execute_reply": "2023-02-20T11:28:05.019979Z",
     "shell.execute_reply.started": "2023-02-20T11:28:05.007015Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You, sir, are my hero. Any chance you remember what page that's on?\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sir hero chance remember page'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"text\"][4])\n",
    "display(df[\"lemm_text\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:28:05.023971Z",
     "iopub.status.busy": "2023-02-20T11:28:05.022973Z",
     "iopub.status.idle": "2023-02-20T11:28:05.066856Z",
     "shell.execute_reply": "2023-02-20T11:28:05.065859Z",
     "shell.execute_reply.started": "2023-02-20T11:28:05.023971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>cannot make real suggestion improvement wonder...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>second time asking view completely contradicts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>spitzer umm there actual article prostitution ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>look like actually put speedy first version de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>really think understand came idea bad right aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...   \n",
       "1       D'aww! He matches this background colour I'm s...   \n",
       "2       Hey man, I'm really not trying to edit war. It...   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       You, sir, are my hero. Any chance you remember...   \n",
       "...                                                   ...   \n",
       "159287  \":::::And for the second time of asking, when ...   \n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159290  And it looks like it was actually you who put ...   \n",
       "159291  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "                                                lemm_text  toxic  \n",
       "0       explanation edits made username hardcore metal...      0  \n",
       "1       aww match background colour seemingly stuck th...      0  \n",
       "2       hey man really trying edit war guy constantly ...      0  \n",
       "3       cannot make real suggestion improvement wonder...      0  \n",
       "4                           sir hero chance remember page      0  \n",
       "...                                                   ...    ...  \n",
       "159287  second time asking view completely contradicts...      0  \n",
       "159288               ashamed horrible thing put talk page      0  \n",
       "159289  spitzer umm there actual article prostitution ...      0  \n",
       "159290  look like actually put speedy first version de...      0  \n",
       "159291  really think understand came idea bad right aw...      0  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"text\", \"lemm_text\", \"toxic\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "1. Текстовые данные загружены и содержат примерно 160_000 строк;\n",
    "2. Тексты очищены и лемматизированы с помощью инструментов библиотек re и nltk.\n",
    "3. В данных наблюдается дисбаланс классов, токсичных комментариев порядка 10 % всего датасета;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на обучающую, валидационную и тестовую выборки в соотношении 60/20/20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:28:05.068849Z",
     "iopub.status.busy": "2023-02-20T11:28:05.067851Z",
     "iopub.status.idle": "2023-02-20T11:28:05.129686Z",
     "shell.execute_reply": "2023-02-20T11:28:05.128690Z",
     "shell.execute_reply.started": "2023-02-20T11:28:05.068849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95574,) (31859,) (31859,)\n"
     ]
    }
   ],
   "source": [
    "X = df[\"lemm_text\"]\n",
    "y = df[\"toxic\"]\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, random_state=RND, test_size=0.2\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=RND, test_size=0.25\n",
    ")\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим дисбаланс классов в получившихся выборках\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:28:05.132678Z",
     "iopub.status.busy": "2023-02-20T11:28:05.131681Z",
     "iopub.status.idle": "2023-02-20T11:28:05.160121Z",
     "shell.execute_reply": "2023-02-20T11:28:05.159123Z",
     "shell.execute_reply.started": "2023-02-20T11:28:05.132678Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_val</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897015</td>\n",
       "      <td>0.898208</td>\n",
       "      <td>0.898906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102985</td>\n",
       "      <td>0.101792</td>\n",
       "      <td>0.101094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test     y_val   y_train\n",
       "0  0.897015  0.898208  0.898906\n",
       "1  0.102985  0.101792  0.101094"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"y_test\": y_test.value_counts(normalize=True),\n",
    "        \"y_val\": y_val.value_counts(normalize=True),\n",
    "        \"y_train\": y_train.value_counts(normalize=True),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обычные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем 5 моделей из библиотеки slearn обучим их и запишем необходимые метрики качества моделей, чтобы в дальнейшем решить, какие из них имеет смысл оптимизировать. Функция test_models, работает в 2 режимах: True необходим для примерной оценки времени обучения и предсказания модели на валидации и оценки кросс-валидации только на обучающих данных, False оценивает данные на тесте, но обучающая выборка состоит из train+val. Фичи из текста для моделей создаёт TfidfVectorizer, который остеивает очень частые и очень редкие слова, а также стоп-слова.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:28:05.162133Z",
     "iopub.status.busy": "2023-02-20T11:28:05.161119Z",
     "iopub.status.idle": "2023-02-20T11:28:05.176077Z",
     "shell.execute_reply": "2023-02-20T11:28:05.175079Z",
     "shell.execute_reply.started": "2023-02-20T11:28:05.162133Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_params = {\"random_state\": RND, \"class_weight\": \"balanced\"}\n",
    "tf_idf = TfidfVectorizer(\n",
    "    ngram_range=(1, 3), min_df=5, max_df=0.8, sublinear_tf=True, stop_words=\"english\"\n",
    ")\n",
    "classifiers = [\n",
    "    LogisticRegression(**default_params),\n",
    "    LinearSVC(**default_params),\n",
    "    SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        max_iter=1000,\n",
    "        penalty=\"l2\",\n",
    "        alpha=1e-5,\n",
    "        tol=1e-3,\n",
    "        **default_params\n",
    "    ),\n",
    "    PassiveAggressiveClassifier(**default_params),\n",
    "    RidgeClassifier(**default_params),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:28:05.179069Z",
     "iopub.status.busy": "2023-02-20T11:28:05.178071Z",
     "iopub.status.idle": "2023-02-20T11:31:18.090845Z",
     "shell.execute_reply": "2023-02-20T11:31:18.089880Z",
     "shell.execute_reply.started": "2023-02-20T11:28:05.179069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training LogisticRegression...\n",
      "\n",
      "Train cross-val: 0.7369407295314486 : [0.74031764 0.73363304 0.73687151]\n",
      "Fit time: 17.444 seconds\n",
      "Prediction time: 3.398 seconds\n",
      "\n",
      "        Metrics:\n",
      "        LogisticRegression accuracy: 0.945\n",
      "        LogisticRegression f1 score: 0.758\n",
      "        LogisticRegression ROC AUC score: 0.902\n",
      "        \n",
      "================================================================================\n",
      "================================================================================\n",
      "Training LinearSVC...\n",
      "\n",
      "Train cross-val: 0.744282890007129 : [0.74372307 0.74320693 0.74591867]\n",
      "Fit time: 15.888 seconds\n",
      "Prediction time: 3.367 seconds\n",
      "\n",
      "        Metrics:\n",
      "        LinearSVC accuracy: 0.949\n",
      "        LinearSVC f1 score: 0.761\n",
      "        LinearSVC ROC AUC score: 0.882\n",
      "        \n",
      "================================================================================\n",
      "================================================================================\n",
      "Training SGDClassifier...\n",
      "\n",
      "Train cross-val: 0.7392924402672728 : [0.74592009 0.73318572 0.73877151]\n",
      "Fit time: 14.857 seconds\n",
      "Prediction time: 3.205 seconds\n",
      "\n",
      "        Metrics:\n",
      "        SGDClassifier accuracy: 0.944\n",
      "        SGDClassifier f1 score: 0.755\n",
      "        SGDClassifier ROC AUC score: 0.904\n",
      "        \n",
      "================================================================================\n",
      "================================================================================\n",
      "Training PassiveAggressiveClassifier...\n",
      "\n",
      "Train cross-val: 0.7168529160198819 : [0.71484559 0.71351694 0.72219623]\n",
      "Fit time: 16.667 seconds\n",
      "Prediction time: 3.107 seconds\n",
      "\n",
      "        Metrics:\n",
      "        PassiveAggressiveClassifier accuracy: 0.948\n",
      "        PassiveAggressiveClassifier f1 score: 0.738\n",
      "        PassiveAggressiveClassifier ROC AUC score: 0.846\n",
      "        \n",
      "================================================================================\n",
      "================================================================================\n",
      "Training RidgeClassifier...\n",
      "\n",
      "Train cross-val: 0.6868323814570173 : [0.69006526 0.68677156 0.68366032]\n",
      "Fit time: 16.251 seconds\n",
      "Prediction time: 3.408 seconds\n",
      "\n",
      "        Metrics:\n",
      "        RidgeClassifier accuracy: 0.934\n",
      "        RidgeClassifier f1 score: 0.699\n",
      "        RidgeClassifier ROC AUC score: 0.852\n",
      "        \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def test_models(classifiers, train_mode=True):\n",
    "    results = []\n",
    "    for clf in classifiers:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Training {clf_name}...\\n\")\n",
    "        pipe = (\n",
    "            clf\n",
    "            if clf_name == \"CatBoostClassifier\"\n",
    "            else Pipeline(steps=[(\"tf_idf\", tf_idf), (\"model\", clf)])\n",
    "        )\n",
    "        features_train = X_train if train_mode else X_train_full\n",
    "        if clf_name == \"CatBoostClassifier\":\n",
    "            features_train = pd.DataFrame(features_train)\n",
    "        target_train = y_train if train_mode else y_train_full\n",
    "        cvs = cross_val_score(\n",
    "            pipe, features_train, target_train, scoring=\"f1\", n_jobs=-1, cv=3\n",
    "        )\n",
    "        print(\"Train cross-val:\", cvs.mean(), \":\", cvs)\n",
    "\n",
    "        fit_start = time.perf_counter()\n",
    "        pipe.fit(features_train, target_train)\n",
    "        fit_time = time.perf_counter() - fit_start\n",
    "        print(f\"Fit time: {fit_time:.3f} seconds\")\n",
    "\n",
    "        features_test = X_val if train_mode else X_test\n",
    "        predict_start = time.perf_counter()\n",
    "        y_pred = pipe.predict(\n",
    "            pd.DataFrame(features_test)\n",
    "            if clf_name == \"CatBoostClassifier\"\n",
    "            else features_test\n",
    "        )\n",
    "        predict_time = time.perf_counter() - predict_start\n",
    "        print(f\"Prediction time: {predict_time:.3f} seconds\")\n",
    "\n",
    "        y_true = y_val if train_mode else y_test\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        Metrics:\n",
    "        {clf_name} accuracy: {accuracy:.3f}\n",
    "        {clf_name} f1 score: {f1:.3f}\n",
    "        {clf_name} ROC AUC score: {roc_auc:.3f}\n",
    "        \"\"\"\n",
    "        )\n",
    "        print(\"=\" * 80)\n",
    "        results.append(\n",
    "            [clf_name, fit_time, predict_time, cvs.mean(), accuracy, f1, roc_auc, pipe]\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "sklearn_clfs = test_models(classifiers, train_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более удобного отображения напишем функцию, создающую из списка датафрейм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:31:18.091842Z",
     "iopub.status.busy": "2023-02-20T11:31:18.091842Z",
     "iopub.status.idle": "2023-02-20T11:31:18.106836Z",
     "shell.execute_reply": "2023-02-20T11:31:18.105838Z",
     "shell.execute_reply.started": "2023-02-20T11:31:18.091842Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_results(results):\n",
    "    columns = [\n",
    "        \"model_name\",\n",
    "        \"fit_time\",\n",
    "        \"pred_time\",\n",
    "        \"cross_val_score_f1\",\n",
    "        \"accuracy\",\n",
    "        \"f1\",\n",
    "        \"AUC_ROC\",\n",
    "        \"model\",\n",
    "    ]\n",
    "    df = (\n",
    "        pd.DataFrame(results, columns=columns)\n",
    "        .drop(\"model\", axis=1)\n",
    "        .sort_values(by=\"cross_val_score_f1\", ascending=False)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:31:18.108795Z",
     "iopub.status.busy": "2023-02-20T11:31:18.108795Z",
     "iopub.status.idle": "2023-02-20T11:31:18.212230Z",
     "shell.execute_reply": "2023-02-20T11:31:18.212230Z",
     "shell.execute_reply.started": "2023-02-20T11:31:18.108795Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2a798_row0_col1 {\n",
       "  background-color: #9ebad9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a798_row0_col2 {\n",
       "  background-color: #045c90;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row0_col3, #T_2a798_row0_col4, #T_2a798_row0_col5, #T_2a798_row1_col6, #T_2a798_row2_col1, #T_2a798_row4_col2 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row0_col6 {\n",
       "  background-color: #3b92c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row1_col1, #T_2a798_row3_col2, #T_2a798_row3_col6, #T_2a798_row4_col3, #T_2a798_row4_col4, #T_2a798_row4_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a798_row1_col2 {\n",
       "  background-color: #b7c5df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2a798_row1_col3 {\n",
       "  background-color: #034f7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row1_col4, #T_2a798_row3_col5 {\n",
       "  background-color: #3991c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row1_col5 {\n",
       "  background-color: #045382;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row2_col2 {\n",
       "  background-color: #034267;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row2_col3 {\n",
       "  background-color: #045a8d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row2_col4 {\n",
       "  background-color: #167bb6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row2_col5 {\n",
       "  background-color: #03466e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row2_col6 {\n",
       "  background-color: #023f64;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row3_col1 {\n",
       "  background-color: #187cb6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row3_col3 {\n",
       "  background-color: #69a5cc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row3_col4 {\n",
       "  background-color: #034a74;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row4_col1 {\n",
       "  background-color: #62a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2a798_row4_col6 {\n",
       "  background-color: #efe9f3;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2a798\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2a798_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th id=\"T_2a798_level0_col1\" class=\"col_heading level0 col1\" >fit_time</th>\n",
       "      <th id=\"T_2a798_level0_col2\" class=\"col_heading level0 col2\" >pred_time</th>\n",
       "      <th id=\"T_2a798_level0_col3\" class=\"col_heading level0 col3\" >cross_val_score_f1</th>\n",
       "      <th id=\"T_2a798_level0_col4\" class=\"col_heading level0 col4\" >accuracy</th>\n",
       "      <th id=\"T_2a798_level0_col5\" class=\"col_heading level0 col5\" >f1</th>\n",
       "      <th id=\"T_2a798_level0_col6\" class=\"col_heading level0 col6\" >AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2a798_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_2a798_row0_col0\" class=\"data row0 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_2a798_row0_col1\" class=\"data row0 col1\" >15.887598</td>\n",
       "      <td id=\"T_2a798_row0_col2\" class=\"data row0 col2\" >3.366891</td>\n",
       "      <td id=\"T_2a798_row0_col3\" class=\"data row0 col3\" >0.744283</td>\n",
       "      <td id=\"T_2a798_row0_col4\" class=\"data row0 col4\" >0.949057</td>\n",
       "      <td id=\"T_2a798_row0_col5\" class=\"data row0 col5\" >0.761007</td>\n",
       "      <td id=\"T_2a798_row0_col6\" class=\"data row0 col6\" >0.881553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a798_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_2a798_row1_col0\" class=\"data row1 col0\" >SGDClassifier</td>\n",
       "      <td id=\"T_2a798_row1_col1\" class=\"data row1 col1\" >14.857276</td>\n",
       "      <td id=\"T_2a798_row1_col2\" class=\"data row1 col2\" >3.205218</td>\n",
       "      <td id=\"T_2a798_row1_col3\" class=\"data row1 col3\" >0.739292</td>\n",
       "      <td id=\"T_2a798_row1_col4\" class=\"data row1 col4\" >0.943501</td>\n",
       "      <td id=\"T_2a798_row1_col5\" class=\"data row1 col5\" >0.754835</td>\n",
       "      <td id=\"T_2a798_row1_col6\" class=\"data row1 col6\" >0.904024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a798_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "      <td id=\"T_2a798_row2_col0\" class=\"data row2 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_2a798_row2_col1\" class=\"data row2 col1\" >17.444447</td>\n",
       "      <td id=\"T_2a798_row2_col2\" class=\"data row2 col2\" >3.397604</td>\n",
       "      <td id=\"T_2a798_row2_col3\" class=\"data row2 col3\" >0.736941</td>\n",
       "      <td id=\"T_2a798_row2_col4\" class=\"data row2 col4\" >0.944725</td>\n",
       "      <td id=\"T_2a798_row2_col5\" class=\"data row2 col5\" >0.757738</td>\n",
       "      <td id=\"T_2a798_row2_col6\" class=\"data row2 col6\" >0.902382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a798_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2a798_row3_col0\" class=\"data row3 col0\" >PassiveAggressiveClassifier</td>\n",
       "      <td id=\"T_2a798_row3_col1\" class=\"data row3 col1\" >16.666684</td>\n",
       "      <td id=\"T_2a798_row3_col2\" class=\"data row3 col2\" >3.107000</td>\n",
       "      <td id=\"T_2a798_row3_col3\" class=\"data row3 col3\" >0.716853</td>\n",
       "      <td id=\"T_2a798_row3_col4\" class=\"data row3 col4\" >0.948052</td>\n",
       "      <td id=\"T_2a798_row3_col5\" class=\"data row3 col5\" >0.737593</td>\n",
       "      <td id=\"T_2a798_row3_col6\" class=\"data row3 col6\" >0.845724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a798_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2a798_row4_col0\" class=\"data row4 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_2a798_row4_col1\" class=\"data row4 col1\" >16.250820</td>\n",
       "      <td id=\"T_2a798_row4_col2\" class=\"data row4 col2\" >3.408354</td>\n",
       "      <td id=\"T_2a798_row4_col3\" class=\"data row4 col3\" >0.686832</td>\n",
       "      <td id=\"T_2a798_row4_col4\" class=\"data row4 col4\" >0.934461</td>\n",
       "      <td id=\"T_2a798_row4_col5\" class=\"data row4 col5\" >0.699222</td>\n",
       "      <td id=\"T_2a798_row4_col6\" class=\"data row4 col6\" >0.851965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x272461660d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results(sklearn_clfs).style.background_gradient(\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по результатам на кросс-валидации, 4 модели можно оптимизировать дальше, чтобы улучшить метрику. Первые 3 модели показывают хорошие результаты по всем 3 метрикам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем оптимизировать эти модели со следующими параметрами:\n",
    "\n",
    "1. LinearSVC: _penalty_ = 'l1'/'l2', _C_ = 1e-6 - 1e4, _dual_ = True/False;\n",
    "2. SGDClassifier: _loss_ = 'hinge'/'log'/'modified*huber'/'squared_hinge'/'perceptron'/'huber'/'epsilon_insensitive', \\_penalty* = 'l1'/'l2', _alpha_ = 1e-8 - 1e4, _validation_fraction_ = 0.01 - 0.99;\n",
    "3. LogisticRegression: _penalty_ = 'l1'/'l2', _C_ = 1e-4 - 1e4, _solver_ = 'lbfgs'/'liblinear'/'newton-cg'/'sag';\n",
    "4. PassiveAgressiveClassifier: _validation_fraction_ = 0.01 - 0.99, _loss_ = 'squared*hinge'/'hinge', \\_average* = 0 - 100, _C_ = 1e-6 - 1e4.\n",
    "\n",
    "Поскольку процесс оптимизации рассчитывался достаточно долго, то я не буду приводить код для каждой модели, а ограничусь лишь общим описанием процесса оптимизации на примере SGDClassifier:\n",
    "\n",
    "```python\n",
    "def objective(trial):\n",
    "    pipe = Pipeline(steps=[('tf_idf', tf_idf), ('model', SGDClassifier(**default_params, eta0=0.1, learning_rate='adaptive', early_stopping=True))])\n",
    "\n",
    "    loss = trial.suggest_categorical('loss', ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'huber', 'epsilon_insensitive'])\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    alpha = trial.suggest_float('alpha', 1e-8, 1e4, log=True)\n",
    "    validation_fraction = trial.suggest_float('validation_fraction', 0.01, 0.99, step=0.01)\n",
    "\n",
    "    pipe.set_params(model__loss=loss, model__penalty=penalty, model__alpha=alpha, model__validation_fraction=validation_fraction)\n",
    "\n",
    "    return cross_val_score(pipe, X_train_full, y_train_full, cv=3, scoring='f1', n_jobs=3).mean()\n",
    "\n",
    "study_sgd_new = optuna.create_study(study_name='new_sgd', direction='maximize')\n",
    "study_sgd_new.optimize(objective, n_trials=100, n_jobs=9)\n",
    "```\n",
    "\n",
    "Далее оптимизированные функции прогонялись через test_models в режиме train_mode=False и результаты архивировались в файл .pkl через pickle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:31:18.214225Z",
     "iopub.status.busy": "2023-02-20T11:31:18.213261Z",
     "iopub.status.idle": "2023-02-20T11:31:21.680510Z",
     "shell.execute_reply": "2023-02-20T11:31:21.679512Z",
     "shell.execute_reply.started": "2023-02-20T11:31:18.214225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_15a59_row0_col1 {\n",
       "  background-color: #bfc9e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_15a59_row0_col2 {\n",
       "  background-color: #b3c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_15a59_row0_col3, #T_15a59_row1_col1, #T_15a59_row1_col2 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_15a59_row1_col3 {\n",
       "  background-color: #9ab8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_15a59_row2_col1 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_15a59_row2_col2 {\n",
       "  background-color: #d7d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_15a59_row2_col3 {\n",
       "  background-color: #e9e5f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_15a59_row3_col1, #T_15a59_row3_col2, #T_15a59_row3_col3 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_15a59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_15a59_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th id=\"T_15a59_level0_col1\" class=\"col_heading level0 col1\" >fit_time</th>\n",
       "      <th id=\"T_15a59_level0_col2\" class=\"col_heading level0 col2\" >pred_time</th>\n",
       "      <th id=\"T_15a59_level0_col3\" class=\"col_heading level0 col3\" >cross_val_score_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_15a59_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_15a59_row0_col0\" class=\"data row0 col0\" >SGDClassifier</td>\n",
       "      <td id=\"T_15a59_row0_col1\" class=\"data row0 col1\" >19.681963</td>\n",
       "      <td id=\"T_15a59_row0_col2\" class=\"data row0 col2\" >2.756154</td>\n",
       "      <td id=\"T_15a59_row0_col3\" class=\"data row0 col3\" >0.765352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15a59_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "      <td id=\"T_15a59_row1_col0\" class=\"data row1 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_15a59_row1_col1\" class=\"data row1 col1\" >25.002347</td>\n",
       "      <td id=\"T_15a59_row1_col2\" class=\"data row1 col2\" >2.972585</td>\n",
       "      <td id=\"T_15a59_row1_col3\" class=\"data row1 col3\" >0.760968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15a59_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_15a59_row2_col0\" class=\"data row2 col0\" >PassiveAggressiveClassifier</td>\n",
       "      <td id=\"T_15a59_row2_col1\" class=\"data row2 col1\" >17.499214</td>\n",
       "      <td id=\"T_15a59_row2_col2\" class=\"data row2 col2\" >2.717646</td>\n",
       "      <td id=\"T_15a59_row2_col3\" class=\"data row2 col3\" >0.759005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15a59_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "      <td id=\"T_15a59_row3_col0\" class=\"data row3 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_15a59_row3_col1\" class=\"data row3 col1\" >17.357877</td>\n",
       "      <td id=\"T_15a59_row3_col2\" class=\"data row3 col2\" >2.645502</td>\n",
       "      <td id=\"T_15a59_row3_col3\" class=\"data row3 col3\" >0.757993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2725c0e0a30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ячейка не выполнится и даст ошибку, если в папке с проектом не будет файла modified_models_list.pkl, ссылки для скачивания в начале\n",
    "modified_models_list = pickle.load(open(\"modified_models_list.pkl\", \"rb\"))\n",
    "df_results(modified_models_list[:-1]).iloc[:, :4].style.background_gradient(\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентные модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве градиетных моделей для данной задачи были выбраны CatBoost и LGBM классификаторы, в силу того, что CatBoost имеет поддержку обработки текстовых данных(если выполнять классификацию в обычном режиме через предложенный в test_models pipeline, то на одну итерацию приходится ~15 мин), LGBM же должен за более разумное время справляться с такими массивами данных(после tf_idf размер данных примерно 120_000x145_000).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём CatBoost классификатор и добавляем его к остальным сохранённым моделям\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:31:21.681507Z",
     "iopub.status.busy": "2023-02-20T11:31:21.681507Z",
     "iopub.status.idle": "2023-02-20T11:41:37.861532Z",
     "shell.execute_reply": "2023-02-20T11:41:37.859536Z",
     "shell.execute_reply.started": "2023-02-20T11:31:21.681507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training CatBoostClassifier...\n",
      "\n",
      "Train cross-val: 0.7673910594510046 : [0.76889177 0.77052795 0.76275345]\n",
      "0:\tlearn: 0.6940104\ttotal: 303ms\tremaining: 5m 2s\n",
      "100:\tlearn: 0.7779708\ttotal: 20.7s\tremaining: 3m 3s\n",
      "200:\tlearn: 0.7984593\ttotal: 39.7s\tremaining: 2m 37s\n",
      "300:\tlearn: 0.8091379\ttotal: 58.4s\tremaining: 2m 15s\n",
      "400:\tlearn: 0.8190836\ttotal: 1m 17s\tremaining: 1m 55s\n",
      "500:\tlearn: 0.8270111\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "600:\tlearn: 0.8349812\ttotal: 1m 53s\tremaining: 1m 15s\n",
      "700:\tlearn: 0.8424224\ttotal: 2m 12s\tremaining: 56.5s\n",
      "800:\tlearn: 0.8514592\ttotal: 2m 35s\tremaining: 38.7s\n",
      "900:\tlearn: 0.8583445\ttotal: 2m 54s\tremaining: 19.1s\n",
      "999:\tlearn: 0.8649872\ttotal: 3m 13s\tremaining: 0us\n",
      "Fit time: 199.625 seconds\n",
      "Prediction time: 0.591 seconds\n",
      "\n",
      "        Metrics:\n",
      "        CatBoostClassifier accuracy: 0.958\n",
      "        CatBoostClassifier f1 score: 0.773\n",
      "        CatBoostClassifier ROC AUC score: 0.841\n",
      "        \n",
      "================================================================================\n",
      "CPU times: total: 25min 54s\n",
      "Wall time: 10min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_cb = CatBoostClassifier(\n",
    "    learning_rate=0.33, text_features=['lemm_text'], eval_metric='F1', \n",
    "    early_stopping_rounds=100, random_seed=RND, verbose=100)\n",
    "all_clfs_results = modified_models_list + test_models([clf_cb], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для конечного выбора модели необходимо скрыть значения метрик на тестовой выборке, в таком случае определяющими параметрами для выбора итогового классификатора будут как и ранее время обучения, предсказания и значение f1 на полной обучающей выборке с кросс-валидацией.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:41:37.863527Z",
     "iopub.status.busy": "2023-02-20T11:41:37.863527Z",
     "iopub.status.idle": "2023-02-20T11:41:37.891553Z",
     "shell.execute_reply": "2023-02-20T11:41:37.890554Z",
     "shell.execute_reply.started": "2023-02-20T11:41:37.863527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9f98d_row0_col1, #T_9f98d_row0_col2, #T_9f98d_row0_col3 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f98d_row1_col1 {\n",
       "  background-color: #cccfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row1_col2, #T_9f98d_row2_col1, #T_9f98d_row4_col1, #T_9f98d_row5_col1, #T_9f98d_row5_col3 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row1_col3 {\n",
       "  background-color: #2c89bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f98d_row2_col2 {\n",
       "  background-color: #b3c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row2_col3 {\n",
       "  background-color: #6fa7ce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f98d_row3_col1 {\n",
       "  background-color: #fef6fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row3_col2 {\n",
       "  background-color: #a8bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row3_col3 {\n",
       "  background-color: #dad9ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row4_col2 {\n",
       "  background-color: #b5c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row4_col3 {\n",
       "  background-color: #f5eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f98d_row5_col2 {\n",
       "  background-color: #b9c6e0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9f98d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9f98d_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th id=\"T_9f98d_level0_col1\" class=\"col_heading level0 col1\" >fit_time</th>\n",
       "      <th id=\"T_9f98d_level0_col2\" class=\"col_heading level0 col2\" >pred_time</th>\n",
       "      <th id=\"T_9f98d_level0_col3\" class=\"col_heading level0 col3\" >cross_val_score_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9f98d_level0_row0\" class=\"row_heading level0 row0\" >4</th>\n",
       "      <td id=\"T_9f98d_row0_col0\" class=\"data row0 col0\" >LGBMClassifier</td>\n",
       "      <td id=\"T_9f98d_row0_col1\" class=\"data row0 col1\" >708.931170</td>\n",
       "      <td id=\"T_9f98d_row0_col2\" class=\"data row0 col2\" >7.029682</td>\n",
       "      <td id=\"T_9f98d_row0_col3\" class=\"data row0 col3\" >0.772423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f98d_level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "      <td id=\"T_9f98d_row1_col0\" class=\"data row1 col0\" >CatBoostClassifier</td>\n",
       "      <td id=\"T_9f98d_row1_col1\" class=\"data row1 col1\" >199.624616</td>\n",
       "      <td id=\"T_9f98d_row1_col2\" class=\"data row1 col2\" >0.590831</td>\n",
       "      <td id=\"T_9f98d_row1_col3\" class=\"data row1 col3\" >0.767391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f98d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9f98d_row2_col0\" class=\"data row2 col0\" >SGDClassifier</td>\n",
       "      <td id=\"T_9f98d_row2_col1\" class=\"data row2 col1\" >19.681963</td>\n",
       "      <td id=\"T_9f98d_row2_col2\" class=\"data row2 col2\" >2.756154</td>\n",
       "      <td id=\"T_9f98d_row2_col3\" class=\"data row2 col3\" >0.765352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f98d_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_9f98d_row3_col0\" class=\"data row3 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_9f98d_row3_col1\" class=\"data row3 col1\" >25.002347</td>\n",
       "      <td id=\"T_9f98d_row3_col2\" class=\"data row3 col2\" >2.972585</td>\n",
       "      <td id=\"T_9f98d_row3_col3\" class=\"data row3 col3\" >0.760968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f98d_level0_row4\" class=\"row_heading level0 row4\" >3</th>\n",
       "      <td id=\"T_9f98d_row4_col0\" class=\"data row4 col0\" >PassiveAggressiveClassifier</td>\n",
       "      <td id=\"T_9f98d_row4_col1\" class=\"data row4 col1\" >17.499214</td>\n",
       "      <td id=\"T_9f98d_row4_col2\" class=\"data row4 col2\" >2.717646</td>\n",
       "      <td id=\"T_9f98d_row4_col3\" class=\"data row4 col3\" >0.759005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f98d_level0_row5\" class=\"row_heading level0 row5\" >1</th>\n",
       "      <td id=\"T_9f98d_row5_col0\" class=\"data row5 col0\" >LinearSVC</td>\n",
       "      <td id=\"T_9f98d_row5_col1\" class=\"data row5 col1\" >17.357877</td>\n",
       "      <td id=\"T_9f98d_row5_col2\" class=\"data row5 col2\" >2.645502</td>\n",
       "      <td id=\"T_9f98d_row5_col3\" class=\"data row5 col3\" >0.757993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2725c0e0f10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clfs_results = df_results(all_clfs_results)\n",
    "df_clfs_results.iloc[:, :4].style.background_gradient(\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комментарии по результатам:\n",
    "\n",
    "1. Скорость обучения - в плане скорости LGBM и CatBoost уступают моделям из sklearn примерно в 35+ и в 7+ раз;\n",
    "2. Скорость предсказания - CatBoost оказался самым быстрым, далее идут sklearn модели с результатом <3 сек и на последнем месте LGBM;\n",
    "3. F1 метрика на кросс-валидации - градиентные модели самые эффективные (дают метрику >0.765), остальные же модели несколько уступают и дают на кроссвалидации от 0.758 до 0.761.\n",
    "\n",
    "В рамках данной задачи компромисным вариантом среди всех предложенных я считаю SGDClassifier, поскольку при соответствующей подготовке и данных и подборе гиперпараметров способен дать метрику не хуже, чем более солидные модели. В качестве альтернативного варианта я бы рассмотрел CatBoost, который при минимальной настройке даёт хорошие метрики и имеет встроенную возможность работы с текстом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T11:41:37.896114Z",
     "iopub.status.busy": "2023-02-20T11:41:37.895135Z",
     "iopub.status.idle": "2023-02-20T11:41:37.924038Z",
     "shell.execute_reply": "2023-02-20T11:41:37.922044Z",
     "shell.execute_reply.started": "2023-02-20T11:41:37.896114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time</th>\n",
       "      <th>cross_val_score_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>19.681963</td>\n",
       "      <td>2.756154</td>\n",
       "      <td>0.765352</td>\n",
       "      <td>0.95138</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.883058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name   fit_time  pred_time  cross_val_score_f1  accuracy      f1  \\\n",
       "2  SGDClassifier  19.681963   2.756154            0.765352   0.95138  0.7715   \n",
       "\n",
       "    AUC_ROC  \n",
       "2  0.883058  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clfs_results.query('model_name == \"SGDClassifier\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, этот классификатор даёт метрику f1 > 0.75. Также следует отметить, что модель на тестовых данных адекватна, поскольку в случае предсказания наиболее частого класса(в данном случае 0) метрика f1, будет равна 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "1. Рассмотрено 6 различных классификатора, 4 из библиотеки sklearn, и 2 сторонние модели градиентого бустинга: LGBMClassifier и CatBoostClassifier;\n",
    "2. Для всех моделей, кроме CatBoostClassifier были подобраны соответствующие гиперпараметры, позволившие увеличить метрику f1 до значения большего, чем 0.75.\n",
    "3. Оптимальной для данной задачи можно считать SGDClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T10:33:15.115630Z",
     "iopub.status.busy": "2023-02-20T10:33:15.115630Z",
     "iopub.status.idle": "2023-02-20T10:33:15.155620Z",
     "shell.execute_reply": "2023-02-20T10:33:15.154624Z",
     "shell.execute_reply.started": "2023-02-20T10:33:15.115630Z"
    },
    "tags": []
   },
   "source": [
    "По результатам данной работы можно сделать следующие выводы:\n",
    "\n",
    "1. Тестовые данные были загружены, очищены и лемматизированы;\n",
    "2. Обучено 6 различных моделей, 2 из которых представляют собой мощные градиентные бустинги, для большинства моделей гиперпараметры были оптимизированы для достижения метрики f1 > 0.75.\n",
    "3. Для дальнейшего использования рекомендована модель SGDClassifier, поскольку она адекватна по скорости обучения и итоговым метрикам. В случае, если необходимо свести подготовку данных к минимуму, стоит рассмотреть возможность использования CatBoostClassifier с активным параметром text_features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код выполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Данные загружены и подготовлены\n",
    "- [x] Модели обучены\n",
    "- [x] Значение метрики _F1_ не меньше 0.75\n",
    "- [x] Выводы написаны\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
